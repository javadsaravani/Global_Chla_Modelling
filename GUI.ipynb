{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023475c4-8cd0-45c8-b239-57ca0c7b7da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javad\\AppData\\Local\\Temp\\ipykernel_10120\\2613228256.py:64: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  raw_data['chl_a'] = raw_data['chl_a'].fillna(method='ffill')\n",
      "C:\\Users\\Javad\\AppData\\Local\\Temp\\ipykernel_10120\\2613228256.py:65: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  raw_data['chl_a'] = raw_data['chl_a'].fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data range from 2002-08-01 00:00:00 to 2024-08-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javad\\AppData\\Local\\Temp\\ipykernel_10120\\2613228256.py:781: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  inputs_torch = torch.tensor([seq[0] for seq in sequences], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, ttk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import numpy as np\n",
    "import torch\n",
    "from kan import KAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from deepkan import SplineLinearLayer\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ExpSineSquared, WhiteKernel\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ExpSineSquared, WhiteKernel\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lag=12\n",
    "def prepare_data(raw_data):\n",
    "    raw_data['date'] = pd.to_datetime(raw_data['date'], errors='coerce')\n",
    "\n",
    "    start_date = raw_data['date'].min()\n",
    "    end_date = raw_data['date'].max()\n",
    "    chl_a_values = raw_data[['chl_a']].values\n",
    "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
    "    raw_data['lof_score'] = lof.fit_predict(chl_a_values)\n",
    "    raw_data = raw_data[raw_data['lof_score'] != -1].drop(columns=['lof_score'])\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='MS')\n",
    "    raw_data.set_index('date', inplace=True)\n",
    "    raw_data = raw_data.reindex(date_range)\n",
    "    missing_dates = raw_data[raw_data['chl_a'].isnull()].index\n",
    "    raw_data['chl_a'] = raw_data['chl_a'].fillna(method='ffill')\n",
    "    raw_data['chl_a'] = raw_data['chl_a'].fillna(method='bfill')\n",
    "    stl = STL(raw_data['chl_a'], seasonal=13)\n",
    "    result = stl.fit()\n",
    "    raw_data['chl_a'] = np.where(raw_data['chl_a'].isnull(), result.trend + result.seasonal, raw_data['chl_a'])\n",
    "    raw_data['chl_a'] = raw_data['chl_a'].interpolate(method='linear')\n",
    "    raw_data['month'] = raw_data.index.month\n",
    "    print(f\"Data range from {start_date} to {end_date}\")\n",
    "    raw_data['month_sin'] = np.sin(2 * np.pi * raw_data['month'] / 12)\n",
    "    raw_data['month_cos'] = np.cos(2 * np.pi * raw_data['month'] / 12)\n",
    "    raw_data = raw_data.drop(['month'], axis=1)\n",
    "    data_LSTM = raw_data.copy()\n",
    "        \n",
    "    # Create lag features\n",
    "    for i in range(1, lag +1):\n",
    "        raw_data[f'yt-{i}'] = raw_data['chl_a'].shift(i)\n",
    "    \n",
    "    raw_data.dropna(inplace=True)\n",
    "    \n",
    "    return raw_data, data_LSTM\n",
    "    \n",
    "class KANTimeSeries(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, num_knots=5, spline_order=3,\n",
    "                 noise_scale=0.1, base_scale=0.1, spline_scale=1.0,\n",
    "                 activation=nn.SiLU, grid_epsilon=1, grid_range=[-1, 1]):\n",
    "        super(KANTimeSeries, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            self.layers.append(SplineLinearLayer(prev_size, hidden_size, num_knots, spline_order,\n",
    "                                                 noise_scale, base_scale, spline_scale,\n",
    "                                                 activation, grid_epsilon, grid_range))\n",
    "            prev_size = hidden_size\n",
    "\n",
    "        self.output_layer = SplineLinearLayer(prev_size, output_size, num_knots, spline_order,\n",
    "                                              noise_scale, base_scale, spline_scale,\n",
    "                                              activation, grid_epsilon, grid_range)\n",
    "\n",
    "    def forward(self, x, update_knots=False):\n",
    "        for layer in self.layers:\n",
    "            if update_knots:\n",
    "                layer._update_knots(x)\n",
    "            x = layer(x)\n",
    "\n",
    "        if update_knots:\n",
    "            self.output_layer._update_knots(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
    "        loss = 0\n",
    "        for layer in self.layers:\n",
    "            loss += layer._regularization_loss(regularize_activation, regularize_entropy)\n",
    "        loss += self.output_layer._regularization_loss(regularize_activation, regularize_entropy)\n",
    "        return loss\n",
    "\n",
    "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
    "        loss = 0\n",
    "        for layer in self.layers:\n",
    "            loss += layer._regularization_loss(regularize_activation, regularize_entropy)\n",
    "        loss += self.output_layer._regularization_loss(regularize_activation, regularize_entropy)\n",
    "        return loss\n",
    "\n",
    "\n",
    "def load_csv():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "    if not file_path:\n",
    "        return\n",
    "    try:\n",
    "        global raw_data\n",
    "        raw_data = pd.read_csv(file_path)\n",
    "        messagebox.showinfo(\"File Loaded\", \"Make sure your data contains 'date' and 'chl_a' columns\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Could not load file: {e}\")\n",
    "\n",
    "\n",
    "def next_step():\n",
    "    if raw_data is None:\n",
    "        messagebox.showwarning(\"Warning\", \"Please load a CSV file first.\")\n",
    "        return\n",
    "    \n",
    "    global data, data_LSTM\n",
    "    data, data_LSTM = prepare_data(raw_data) \n",
    "    \n",
    "    for widget in frame.winfo_children():\n",
    "        widget.destroy()\n",
    "    \n",
    "    label = tk.Label(frame, text=\"Select a Model:\")\n",
    "    label.pack(pady=10)\n",
    "    \n",
    "    models = [\"KAN\", \"MLP-NN\", \"LSTM\", \"GRU\", \"RF\", \"GPR\", \"SVR\"]\n",
    "    model_var.set(models[0])\n",
    "    \n",
    "    dropdown = tk.OptionMenu(frame, model_var, *models)\n",
    "    dropdown.pack(pady=10)\n",
    "    \n",
    "    next_button = tk.Button(frame, text=\"Run Model\", command=run_model)\n",
    "    next_button.pack(pady=10)\n",
    "    \n",
    "\n",
    "\n",
    "def plot_actual_vs_predicted(actual, predicted, model=None, data=None, forecast_steps=6, selected_model=None):\n",
    "\n",
    "    for widget in frame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    ax.plot(actual, label='Actual', color='blue')\n",
    "    ax.plot(predicted, label='Predicted', color='red', linestyle='--')\n",
    "    ax.set_title('Actual vs. Predicted - Test Data')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Chl-a')\n",
    "    ax.legend()\n",
    "\n",
    "    canvas = FigureCanvasTkAgg(fig, master=frame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack()\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    metrics_text = f\"MAE: {mae:.4f} | MSE: {mse:.4f} | R2: {r2:.4f}\"\n",
    "    metrics_label = tk.Label(frame, text=metrics_text)\n",
    "    metrics_label.pack(pady=10)\n",
    "\n",
    "    if model is not None and data is not None:\n",
    "        forecast_button = None  \n",
    "        if selected_model == 'MLP-NN':\n",
    "            forecast_button = tk.Button(frame, text=\"Forecast\", command=lambda: MLP_forecast_and_plot(model, data, actual, predicted, forecast_steps))\n",
    "        elif selected_model == 'KAN':\n",
    "            forecast_button = tk.Button(frame, text=\"Forecast\", command=lambda: KAN_forecast_and_plot(model, data, actual, predicted, forecast_steps))\n",
    "        elif selected_model == 'LSTM':\n",
    "            forecast_button = tk.Button(frame, text=\"Forecast\", command=lambda: LSTM_forecast_and_plot(model, data, actual, predicted, forecast_steps))\n",
    "        elif selected_model == 'GRU':\n",
    "            forecast_button = tk.Button(frame, text=\"Forecast\", command=lambda: GRU_forecast_and_plot(model, data, actual, predicted, forecast_steps))\n",
    "        elif selected_model == 'RF':  \n",
    "            forecast_button = tk.Button(frame, text=\"Forecast\", command=lambda: RF_forecast_and_plot(model, data, actual, predicted, forecast_steps))\n",
    "        elif selected_model == 'GPR':\n",
    "            forecast_button = tk.Button(frame, text=\"Forecast\", command=lambda: GPR_forecast_and_plot(model, data, actual, predicted, forecast_steps))\n",
    "        elif selected_model == 'SVR':\n",
    "            forecast_button = tk.Button(frame, text=\"Forecast\", command=lambda: SVR_forecast_and_plot(model, data, actual, predicted, forecast_steps))\n",
    "\n",
    "\n",
    "        if forecast_button is not None:\n",
    "            forecast_button.pack(pady=10)\n",
    "\n",
    "    return_button = tk.Button(frame, text=\"Return\", command=next_step)\n",
    "    return_button.pack(pady=10)\n",
    "\n",
    "def calculate_month_cyclic_features(date):\n",
    "    month = date.month\n",
    "    month_sin = np.sin(2 * np.pi * month / 12)\n",
    "    month_cos = np.cos(2 * np.pi * month / 12)\n",
    "    return month_sin, month_cos\n",
    "\n",
    "def prepare_forecast_input(last_lag_values, forecast_dates, i):\n",
    "    month_sin, month_cos = calculate_month_cyclic_features(forecast_dates[i])\n",
    "\n",
    "    forecast_input = np.hstack([last_lag_values, month_sin, month_cos])\n",
    "\n",
    "    return forecast_input\n",
    "\n",
    "def MLP_forecast_next_records(model, data, lag=12, forecast_steps=6):\n",
    "    last_lag_values = data['chl_a'].values[-lag:].flatten()\n",
    "\n",
    "  \n",
    "    last_date = data.index[-1]\n",
    "    forecast_dates = [last_date + pd.DateOffset(months=i) for i in range(1, forecast_steps + 1)]\n",
    "\n",
    "    forecast_values = []\n",
    "    scaler_y = StandardScaler()\n",
    "    scaler_y.fit(data[['chl_a']].values)\n",
    "\n",
    "\n",
    "    for i in range(forecast_steps):\n",
    " \n",
    "        month_sin, month_cos = calculate_month_cyclic_features(forecast_dates[i])\n",
    "\n",
    "        forecast_input = np.hstack([last_lag_values, month_sin, month_cos])\n",
    "        forecast_input_tensor = torch.tensor(forecast_input, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            forecast_value_scaled = model(forecast_input_tensor).cpu().numpy().flatten()[0]\n",
    "\n",
    "        forecast_value = scaler_y.inverse_transform(np.array([[forecast_value_scaled]])).flatten()[0]\n",
    "\n",
    "        forecast_values.append(forecast_value)\n",
    "\n",
    "        last_lag_values = np.roll(last_lag_values, -1)  \n",
    "        last_lag_values[-1] = forecast_value \n",
    "\n",
    "    return forecast_values, forecast_dates\n",
    "\n",
    "def MLP_forecast_and_plot(model, data, actual, predicted, forecast_steps=6):\n",
    "    forecast_values, forecast_dates = MLP_forecast_next_records(model, data, lag=lag, forecast_steps=forecast_steps)\n",
    "\n",
    "    extended_actual = np.append(actual, [None] * forecast_steps)  \n",
    "    extended_predicted = np.append(predicted, forecast_values) \n",
    "\n",
    "    for widget in frame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    ax.plot(extended_actual, label='Actual', color='blue')\n",
    "    ax.plot(extended_predicted[:len(predicted)], label='Predicted', color='red', linestyle='--')\n",
    "    ax.plot(range(len(predicted), len(extended_predicted)), extended_predicted[len(predicted):], label='Forecast', color='green', linestyle='--')\n",
    "    ax.set_title('Actual vs. Predicted - Including Forecast')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Chl-a')\n",
    "    ax.legend()\n",
    "\n",
    "    canvas = FigureCanvasTkAgg(fig, master=frame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack()\n",
    "\n",
    "    plt.close(fig)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    metrics_text = f\"MAE: {mae:.4f} | MSE: {mse:.4f} | R2: {r2:.4f}\"\n",
    "    metrics_label = tk.Label(frame, text=metrics_text)\n",
    "    metrics_label.pack(pady=10)\n",
    "\n",
    "    return_button = tk.Button(frame, text=\"Return\", command=next_step)\n",
    "    return_button.pack(pady=10)\n",
    "\n",
    "def KAN_forecast_next_records(model, last_window, n_steps, window_size, start_date):\n",
    "    forecasts = []\n",
    "    current_window = last_window.copy().values  \n",
    "    current_date = start_date\n",
    "\n",
    "    for _ in range(n_steps):\n",
    "      \n",
    "        current_window_torch = torch.tensor(current_window.reshape(1, window_size * 3), dtype=torch.float32)\n",
    "\n",
    "   \n",
    "        with torch.no_grad():\n",
    "            next_pred = model(current_window_torch).item()  \n",
    "\n",
    "   \n",
    "        forecasts.append(next_pred)\n",
    "\n",
    "    \n",
    "        current_date += pd.DateOffset(months=1)  \n",
    "        month_sin, month_cos = calculate_month_cyclic_features(current_date)\n",
    "\n",
    "    \n",
    "        next_input = np.array([next_pred, month_sin, month_cos]) \n",
    "        current_window = np.vstack((current_window[1:], next_input))  \n",
    "\n",
    "    return forecasts\n",
    "\n",
    "\n",
    "def KAN_forecast_and_plot(model, data, actual, predicted, forecast_steps=6):\n",
    "    last_window = data[-12:] \n",
    "    start_date = pd.to_datetime(data.index[-1])\n",
    "    \n",
    "    forecast_values = KAN_forecast_next_records(model, last_window, forecast_steps, window_size=12, start_date=start_date)\n",
    "\n",
    "    extended_actual = np.append(actual, [None] * forecast_steps) \n",
    "    extended_predicted = np.append(predicted, forecast_values) \n",
    "\n",
    "    for widget in frame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    ax.plot(extended_actual, label='Actual', color='blue')\n",
    "    ax.plot(extended_predicted[:len(predicted)], label='Predicted', color='red', linestyle='--')\n",
    "    ax.plot(range(len(predicted), len(extended_predicted)), extended_predicted[len(predicted):], label='Forecast', color='green', linestyle='--')\n",
    "    ax.set_title('Actual vs. Predicted - Including Forecast')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Chl-a')\n",
    "    ax.legend()\n",
    "    canvas = FigureCanvasTkAgg(fig, master=frame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack()\n",
    "\n",
    "    plt.close(fig)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    metrics_text = f\"MAE: {mae:.4f} | MSE: {mse:.4f} | R2: {r2:.4f}\"\n",
    "    metrics_label = tk.Label(frame, text=metrics_text)\n",
    "    metrics_label.pack(pady=10)\n",
    "\n",
    "    return_button = tk.Button(frame, text=\"Return\", command=next_step)\n",
    "    return_button.pack(pady=10)\n",
    "\n",
    "def LSTM_forecast_next_records(model, data, time_steps=12, forecast_steps=6):\n",
    "    last_window = data['chl_a'].values[-time_steps:].reshape(-1, 1)\n",
    "    month_sin = data['month_sin'].values[-time_steps:]\n",
    "    month_cos = data['month_cos'].values[-time_steps:]\n",
    "\n",
    "    last_window = np.hstack([last_window, month_sin.reshape(-1, 1), month_cos.reshape(-1, 1)])\n",
    "    \n",
    "    forecasts = []\n",
    "    \n",
    "    model_input = torch.tensor(last_window.reshape(1, time_steps, 3), dtype=torch.float32).to(device)\n",
    "    \n",
    "    for _ in range(forecast_steps):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            forecast_value_scaled = model(model_input).cpu().numpy().flatten()[0]\n",
    "        \n",
    "        scaler_y = StandardScaler()\n",
    "        scaler_y.fit(data[['chl_a']].values)\n",
    "        forecast_value = scaler_y.inverse_transform(np.array([[forecast_value_scaled]])).flatten()[0]\n",
    "\n",
    "        forecasts.append(forecast_value)\n",
    "\n",
    "        next_month_sin = np.sin(2 * np.pi * ((month_sin[-1] + 1) % 12) / 12)\n",
    "        next_month_cos = np.cos(2 * np.pi * ((month_cos[-1] + 1) % 12) / 12)\n",
    "        next_input = np.array([forecast_value, next_month_sin, next_month_cos]).reshape(1, 1, -1)\n",
    "        \n",
    "        model_input = torch.cat((model_input[:, 1:, :], torch.tensor(next_input, dtype=torch.float32).to(device)), dim=1)\n",
    "\n",
    "    return forecasts\n",
    "\n",
    "def LSTM_forecast_and_plot(model, data, actual, predicted, forecast_steps=6):\n",
    "    forecast_values = LSTM_forecast_next_records(model, data, time_steps=lag, forecast_steps=forecast_steps)\n",
    "    \n",
    "    extended_actual = np.append(actual, [None] * forecast_steps) \n",
    "    extended_predicted = np.append(predicted, forecast_values) \n",
    "\n",
    "    for widget in frame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    ax.plot(extended_actual, label='Actual', color='blue')\n",
    "    ax.plot(extended_predicted[:len(predicted)], label='Predicted', color='red', linestyle='--')\n",
    "    ax.plot(range(len(predicted), len(extended_predicted)), extended_predicted[len(predicted):], label='Forecast', color='green', linestyle='--')\n",
    "    ax.set_title('Actual vs. Predicted - Including Forecast')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Chl-a')\n",
    "    ax.legend()\n",
    "\n",
    "    canvas = FigureCanvasTkAgg(fig, master=frame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack()\n",
    "\n",
    "    plt.close(fig)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    metrics_text = f\"MAE: {mae:.4f} | MSE: {mse:.4f} | R2: {r2:.4f}\"\n",
    "    metrics_label = tk.Label(frame, text=metrics_text)\n",
    "    metrics_label.pack(pady=10)\n",
    "\n",
    "    return_button = tk.Button(frame, text=\"Return\", command=next_step)\n",
    "    return_button.pack(pady=10)\n",
    "\n",
    "def prepare_data_with_time_steps(data_LSTM, time_steps=12):\n",
    "    chl_a_values = data_LSTM['chl_a'].values\n",
    "    month_sin = data_LSTM['month_sin'].values\n",
    "    month_cos = data_LSTM['month_cos'].values\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(len(chl_a_values) - time_steps):\n",
    "        X.append(\n",
    "               np.hstack([chl_a_values[i:i + time_steps].reshape(-1, 1), \n",
    "               np.tile([month_sin[i + time_steps], month_cos[i + time_steps]], (time_steps, 1))])\n",
    "        )\n",
    "\n",
    "        y.append(chl_a_values[i + time_steps])  \n",
    "\n",
    "    X, y = np.array(X), np.array(y).reshape(-1, 1)\n",
    "    \n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    X = X.reshape(X.shape[0], -1) \n",
    "    X = scaler_X.fit_transform(X) \n",
    "    X = X.reshape(X.shape[0], time_steps, -1)  \n",
    "    y = scaler_y.fit_transform(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=False\n",
    "    )\n",
    "    \n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32, device=device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32, device=device)\n",
    "\n",
    "    return X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, scaler_y\n",
    "\n",
    "def GRU_forecast_next_records(model, data, time_steps=12, forecast_steps=6):\n",
    "    last_window = data['chl_a'].values[-time_steps:].reshape(-1, 1)\n",
    "    month_sin = data['month_sin'].values[-time_steps:]\n",
    "    month_cos = data['month_cos'].values[-time_steps:]\n",
    "    last_window = np.hstack([last_window, month_sin.reshape(-1, 1), month_cos.reshape(-1, 1)])\n",
    "    forecasts = []\n",
    "    \n",
    "\n",
    "    model_input = torch.tensor(last_window.reshape(1, time_steps, 3), dtype=torch.float32).to(device)\n",
    "    \n",
    "    for _ in range(forecast_steps):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            forecast_value_scaled = model(model_input).cpu().numpy().flatten()[0]\n",
    "        \n",
    "        scaler_y = StandardScaler()\n",
    "        scaler_y.fit(data[['chl_a']].values)\n",
    "        forecast_value = scaler_y.inverse_transform(np.array([[forecast_value_scaled]])).flatten()[0]\n",
    "\n",
    "        forecasts.append(forecast_value)\n",
    "\n",
    "        next_month_sin = np.sin(2 * np.pi * ((month_sin[-1] + 1) % 12) / 12)\n",
    "        next_month_cos = np.cos(2 * np.pi * ((month_cos[-1] + 1) % 12) / 12)\n",
    "        next_input = np.array([forecast_value, next_month_sin, next_month_cos]).reshape(1, 1, -1)\n",
    "        \n",
    "        model_input = torch.cat((model_input[:, 1:, :], torch.tensor(next_input, dtype=torch.float32).to(device)), dim=1)\n",
    "\n",
    "    return forecasts\n",
    "\n",
    "def GRU_forecast_and_plot(model, data, actual, predicted, forecast_steps=6):\n",
    "    forecast_values = GRU_forecast_next_records(model, data, time_steps=lag, forecast_steps=forecast_steps)\n",
    "\n",
    "    extended_actual = np.append(actual, [None] * forecast_steps)\n",
    "    extended_predicted = np.append(predicted, forecast_values)  \n",
    "    for widget in frame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "  \n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    ax.plot(extended_actual, label='Actual', color='blue')\n",
    "    ax.plot(extended_predicted[:len(predicted)], label='Predicted', color='red', linestyle='--')\n",
    "    ax.plot(range(len(predicted), len(extended_predicted)), extended_predicted[len(predicted):], label='Forecast', color='green', linestyle='--')\n",
    "    ax.set_title('Actual vs. Predicted - Including Forecast')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Chl-a')\n",
    "    ax.legend()\n",
    "\n",
    " \n",
    "    canvas = FigureCanvasTkAgg(fig, master=frame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack()\n",
    "\n",
    "   \n",
    "    plt.close(fig)\n",
    "      \n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    metrics_text = f\"MAE: {mae:.4f} | MSE: {mse:.4f} | R2: {r2:.4f}\"\n",
    "    metrics_label = tk.Label(frame, text=metrics_text)\n",
    "    metrics_label.pack(pady=10)\n",
    "\n",
    " \n",
    "    return_button = tk.Button(frame, text=\"Return\", command=next_step)\n",
    "    return_button.pack(pady=10)\n",
    "\n",
    "\n",
    "\n",
    "def RF_forecast_next_records(model, last_lag_values, n_steps, lag, forecast_dates):\n",
    "    forecasts = []\n",
    "    current_lag_values = last_lag_values.copy()\n",
    "\n",
    "    for i in range(n_steps):\n",
    "       \n",
    "        forecast_input = np.hstack([current_lag_values, forecast_dates[i][0], forecast_dates[i][1]])\n",
    "        forecast_value_scaled = model.predict(forecast_input.reshape(1, -1)).flatten()[0]\n",
    "        forecasts.append(forecast_value_scaled)\n",
    "        current_lag_values = np.roll(current_lag_values, -1)\n",
    "        current_lag_values[-1] = forecast_value_scaled\n",
    "\n",
    "    return forecasts\n",
    "\n",
    "\n",
    "def RF_forecast_and_plot(model, data, actual, predicted, forecast_steps=6):\n",
    "    print(\"RF forecast and plot function called.\")\n",
    "    last_lag_values = data[['chl_a']].values[-lag:].flatten()\n",
    "    last_date = data.index[-1]\n",
    "    forecast_dates = [calculate_month_cyclic_features(last_date + pd.DateOffset(months=i)) for i in range(1, forecast_steps + 1)]\n",
    "\n",
    "   \n",
    "    next_6_predictions_rf = RF_forecast_next_records(model, last_lag_values, forecast_steps, lag, forecast_dates)\n",
    "\n",
    "   \n",
    "    extended_actual = np.append(actual, [None] * forecast_steps) \n",
    "    extended_predicted = np.append(predicted, next_6_predictions_rf)  \n",
    "\n",
    "  \n",
    "    for widget in frame.winfo_children():\n",
    "        widget.destroy()\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    ax.plot(extended_actual, label='Actual', color='blue')\n",
    "    ax.plot(extended_predicted[:len(predicted)], label='Predicted', color='red', linestyle='--')\n",
    "    ax.plot(range(len(predicted), len(extended_predicted)), extended_predicted[len(predicted):], label='Forecast', color='green', linestyle='--')\n",
    "    ax.set_title('Actual vs. Predicted - Including Forecast')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Chl-a')\n",
    "    ax.legend()\n",
    "    canvas = FigureCanvasTkAgg(fig, master=frame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack()\n",
    "    plt.close(fig)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    metrics_text = f\"MAE: {mae:.4f} | MSE: {mse:.4f} | R2: {r2:.4f}\"\n",
    "    metrics_label = tk.Label(frame, text=metrics_text)\n",
    "    metrics_label.pack(pady=10)\n",
    "    return_button = tk.Button(frame, text=\"Return\", command=next_step)\n",
    "    return_button.pack(pady=10)\n",
    "\n",
    "\n",
    "def GPR_forecast_next_records(model, last_lag_values, n_steps, lag, forecast_dates):\n",
    "    forecasts = []\n",
    "    current_lag_values = last_lag_values.copy()\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        forecast_input = np.hstack([current_lag_values, forecast_dates[i][0], forecast_dates[i][1]])\n",
    "        forecast_value_scaled = model.predict(forecast_input.reshape(1, -1)).flatten()[0]\n",
    "        forecasts.append(forecast_value_scaled)\n",
    "        current_lag_values = np.roll(current_lag_values, -1)\n",
    "        current_lag_values[-1] = forecast_value_scaled\n",
    "\n",
    "    return forecasts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def GPR_forecast_and_plot(model, data, actual, predicted, forecast_steps=6):\n",
    "    print(\"GPR forecast and plot function called.\")\n",
    "    last_lag_values = data[['chl_a']].values[-lag:].flatten()\n",
    "    last_date = data.index[-1]\n",
    "    forecast_dates = [calculate_month_cyclic_features(last_date + pd.DateOffset(months=i)) for i in range(1, forecast_steps + 1)]\n",
    "\n",
    "    next_6_predictions_rf = GPR_forecast_next_records(model, last_lag_values, forecast_steps, lag, forecast_dates)\n",
    "\n",
    "    extended_actual = np.append(actual, [None] * forecast_steps)  \n",
    "    extended_predicted = np.append(predicted, next_6_predictions_rf)  \n",
    "\n",
    "    for widget in frame.winfo_children():\n",
    "        widget.destroy()\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    ax.plot(extended_actual, label='Actual', color='blue')\n",
    "    ax.plot(extended_predicted[:len(predicted)], label='Predicted', color='red', linestyle='--')\n",
    "    ax.plot(range(len(predicted), len(extended_predicted)), extended_predicted[len(predicted):], label='Forecast', color='green', linestyle='--')\n",
    "    ax.set_title('Actual vs. Predicted - Including Forecast')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Chl-a')\n",
    "    ax.legend()\n",
    "    canvas = FigureCanvasTkAgg(fig, master=frame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack()\n",
    "\n",
    "    plt.close(fig)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    metrics_text = f\"MAE: {mae:.4f} | MSE: {mse:.4f} | R2: {r2:.4f}\"\n",
    "    metrics_label = tk.Label(frame, text=metrics_text)\n",
    "    metrics_label.pack(pady=10)\n",
    "    return_button = tk.Button(frame, text=\"Return\", command=next_step)\n",
    "    return_button.pack(pady=10)\n",
    "\n",
    "\n",
    "def SVR_forecast_next_records(model, last_lag_values, n_steps, lag, forecast_dates):\n",
    "    forecasts = []\n",
    "    current_lag_values = last_lag_values.copy()\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        forecast_input = np.hstack([current_lag_values, forecast_dates[i][0], forecast_dates[i][1]])\n",
    "\n",
    "        forecast_value_scaled = model.predict(forecast_input.reshape(1, -1)).flatten()[0]\n",
    "        forecasts.append(forecast_value_scaled)\n",
    "        current_lag_values = np.roll(current_lag_values, -1)\n",
    "        current_lag_values[-1] = forecast_value_scaled\n",
    "\n",
    "    return forecasts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def SVR_forecast_and_plot(model, data, actual, predicted, forecast_steps=6):\n",
    "\n",
    "    print(\"SVR forecast and plot function called.\")\n",
    "    last_lag_values = data[['chl_a']].values[-lag:].flatten()\n",
    "    last_date = data.index[-1]\n",
    "    forecast_dates = [calculate_month_cyclic_features(last_date + pd.DateOffset(months=i)) for i in range(1, forecast_steps + 1)]\n",
    "\n",
    "\n",
    "    next_6_predictions_rf = SVR_forecast_next_records(model, last_lag_values, forecast_steps, lag, forecast_dates)\n",
    "\n",
    "\n",
    "    extended_actual = np.append(actual, [None] * forecast_steps) \n",
    "    extended_predicted = np.append(predicted, next_6_predictions_rf) \n",
    "\n",
    "\n",
    "    for widget in frame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    ax.plot(extended_actual, label='Actual', color='blue')\n",
    "    ax.plot(extended_predicted[:len(predicted)], label='Predicted', color='red', linestyle='--')\n",
    "    ax.plot(range(len(predicted), len(extended_predicted)), extended_predicted[len(predicted):], label='Forecast', color='green', linestyle='--')\n",
    "    ax.set_title('Actual vs. Predicted - Including Forecast')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Chl-a')\n",
    "    ax.legend()\n",
    "\n",
    "    canvas = FigureCanvasTkAgg(fig, master=frame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack()\n",
    "\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    metrics_text = f\"MAE: {mae:.4f} | MSE: {mse:.4f} | R2: {r2:.4f}\"\n",
    "    metrics_label = tk.Label(frame, text=metrics_text)\n",
    "    metrics_label.pack(pady=10)\n",
    "\n",
    "    return_button = tk.Button(frame, text=\"Return\", command=next_step)\n",
    "    return_button.pack(pady=10)\n",
    "\n",
    "\n",
    "def run_model():\n",
    "    selected_model = model_var.get()\n",
    "    lag=12\n",
    "\n",
    "    if selected_model in ['MLP-NN', 'RF', 'GPR', 'SVR']:\n",
    "\n",
    "        X = data[[f'yt-{i}' for i in range(1, lag + 1)] + ['month_sin', 'month_cos']].values\n",
    "        y = data['chl_a'].values\n",
    "\n",
    "    elif selected_model in ['LSTM', 'GRU', 'KAN']:\n",
    "\n",
    "        X = data_LSTM[['chl_a', 'month_sin', 'month_cos']].values\n",
    "        y = data_LSTM['chl_a'].values\n",
    "\n",
    "    else:\n",
    "        messagebox.showerror(\"Error\", \"Model not supported.\")\n",
    "        return\n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False, random_state=42)\n",
    "    \n",
    "\n",
    "    if selected_model == 'MLP-NN':\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        class ANNModel(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(ANNModel, self).__init__()\n",
    "                self.fc1 = nn.Linear(14, 64) \n",
    "                self.relu = nn.ReLU()\n",
    "                self.fc2 = nn.Linear(64, 1) \n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.fc1(x)\n",
    "                x = self.relu(x)\n",
    "                x = self.fc2(x)\n",
    "                return x\n",
    "\n",
    "        def train_and_evaluate_ann():\n",
    "            model = ANNModel()\n",
    "\n",
    "          \n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "  \n",
    "            num_epochs = 50\n",
    "            for epoch in range(num_epochs):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(X_train_tensor)\n",
    "                loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                predictions_train = model(X_train_tensor).numpy()\n",
    "                predictions_test = model(X_test_tensor).numpy()\n",
    "                actual_train = y_train_tensor.numpy()\n",
    "                actual_test = y_test_tensor.numpy()\n",
    "\n",
    "            return model, predictions_train, actual_train, predictions_test, actual_test\n",
    "        \n",
    "        model, predictions_train, actual_train, predictions_test, actual_test = train_and_evaluate_ann()\n",
    "        plot_actual_vs_predicted(actual_test.flatten(), predictions_test.flatten(), model=model, data=data, forecast_steps=6, selected_model='MLP-NN')\n",
    "   \n",
    "    elif selected_model == 'KAN':\n",
    "\n",
    "        dat_KAN = data_LSTM[['chl_a', 'month_sin', 'month_cos']].values.astype(np.float32)\n",
    "\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        data_normalized = scaler.fit_transform(dat_KAN)\n",
    "\n",
    "        def create_sequences(dat_KAN, window_size):\n",
    "            sequences = []\n",
    "            for i in range(len(dat_KAN) - window_size):\n",
    "                input_seq = dat_KAN[i:i + window_size]\n",
    "                output = dat_KAN[i + window_size, 0] \n",
    "                sequences.append((input_seq, output))\n",
    "            return sequences\n",
    "\n",
    "        window_size = 12\n",
    "        sequences = create_sequences(data_normalized, window_size)\n",
    "        inputs_torch = torch.tensor([seq[0] for seq in sequences], dtype=torch.float32)\n",
    "        targets_torch = torch.tensor([seq[1] for seq in sequences], dtype=torch.float32)\n",
    "\n",
    "        split_idx = int(len(inputs_torch) * 0.8)\n",
    "        train_inputs_torch = inputs_torch[:split_idx]\n",
    "        test_inputs_torch = inputs_torch[split_idx:]\n",
    "        train_targets_torch = targets_torch[:split_idx]\n",
    "        test_targets_torch = targets_torch[split_idx:]\n",
    "\n",
    "        input_size = window_size * 3\n",
    "        hidden_sizes = [32]\n",
    "        num_knots = 5\n",
    "        spline_order = 3\n",
    "        model_torch = KANTimeSeries(input_size, hidden_sizes, 1, num_knots, spline_order)\n",
    "\n",
    "        optimizer_torch = torch.optim.Adam(model_torch.parameters(), lr=0.01)\n",
    "        criterion_torch = torch.nn.MSELoss()\n",
    "\n",
    "        epochs = 10\n",
    "        for epoch in range(epochs):\n",
    "            model_torch.train()\n",
    "            epoch_loss = 0\n",
    "            for i in range(len(train_inputs_torch)):\n",
    "                optimizer_torch.zero_grad()\n",
    "                output = model_torch(train_inputs_torch[i:i + 1].view(1, -1))\n",
    "                target = train_targets_torch[i].view_as(output)\n",
    "                loss = criterion_torch(output, target)\n",
    "                loss.backward()\n",
    "                optimizer_torch.step()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "        model_torch.eval()\n",
    "        with torch.no_grad():\n",
    "            train_pred_torch = model_torch(train_inputs_torch.view(len(train_inputs_torch), -1)).squeeze().numpy()\n",
    "            test_pred_torch = model_torch(test_inputs_torch.view(len(test_inputs_torch), -1)).squeeze().numpy()\n",
    "        test_pred_denorm_torch = scaler.inverse_transform(np.hstack([test_pred_torch.reshape(-1, 1), np.zeros((len(test_pred_torch), 2))]))[:, 0]\n",
    "        test_actual_denorm_torch = scaler.inverse_transform(np.hstack([test_targets_torch.numpy().reshape(-1, 1), np.zeros((len(test_targets_torch), 2))]))[:, 0]\n",
    "\n",
    "        plot_actual_vs_predicted(test_actual_denorm_torch, test_pred_denorm_torch, model=model_torch, data=data_LSTM, forecast_steps=6, selected_model='KAN')\n",
    "\n",
    "\n",
    "    elif selected_model == 'LSTM':\n",
    "        class LSTMModel(nn.Module):\n",
    "            def __init__(self, input_size, hidden_size, output_size):\n",
    "                super(LSTMModel, self).__init__()\n",
    "                self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, dropout=0)\n",
    "                self.fc = nn.Linear(hidden_size, output_size)\n",
    "            \n",
    "            def forward(self, x):\n",
    "                lstm_out, _ = self.lstm(x)\n",
    "                lstm_out = lstm_out[:, -1, :]\n",
    "                out = self.fc(lstm_out)\n",
    "                return out\n",
    "        def train_and_evaluate_lstm(X_train, y_train, X_test, y_test, input_size, hidden_size, output_size, num_epochs=100, lr=0.01):\n",
    "            lstm_model = LSTMModel(input_size=input_size, hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = torch.optim.Adam(lstm_model.parameters(), lr=lr)\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                lstm_model.train()\n",
    "                optimizer.zero_grad()\n",
    "                output = lstm_model(X_train)\n",
    "                loss = criterion(output, y_train)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            lstm_model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_train_pred = lstm_model(X_train).cpu().numpy()\n",
    "                y_test_pred = lstm_model(X_test).cpu().numpy()\n",
    "        \n",
    "            return y_train_pred, y_test_pred, y_train.cpu().numpy(), y_test.cpu().numpy(), lstm_model\n",
    "        time_steps = lag \n",
    "        input_size = 3 \n",
    "        hidden_size = 32\n",
    "        output_size = 1\n",
    "    \n",
    "        X_train, y_train, X_test, y_test, scaler_y = prepare_data_with_time_steps(data_LSTM, time_steps=time_steps)\n",
    "    \n",
    "        y_train_pred, y_test_pred, y_train_actual, y_test_actual, lstm_model = train_and_evaluate_lstm(\n",
    "            X_train, y_train, X_test, y_test, input_size, hidden_size, output_size, num_epochs=100, lr=0.01\n",
    "        )\n",
    "    \n",
    "        y_train_pred = scaler_y.inverse_transform(y_train_pred)\n",
    "        y_test_pred = scaler_y.inverse_transform(y_test_pred)\n",
    "        y_train_actual = scaler_y.inverse_transform(y_train_actual)\n",
    "        y_test_actual = scaler_y.inverse_transform(y_test_actual)\n",
    "    \n",
    "        y_train_pred = y_train_pred.flatten()\n",
    "        y_test_pred = y_test_pred.flatten()\n",
    "        y_train_actual = y_train_actual.flatten()\n",
    "        y_test_actual = y_test_actual.flatten()\n",
    "    \n",
    "        plot_actual_vs_predicted(\n",
    "            y_test_actual,\n",
    "            y_test_pred,\n",
    "            model=lstm_model,\n",
    "            data=data_LSTM,\n",
    "            forecast_steps=6,\n",
    "            selected_model='LSTM'\n",
    "        )\n",
    "    elif selected_model == 'GRU':\n",
    "        class GRUModel(nn.Module):\n",
    "            def __init__(self, input_size, hidden_size, output_size):\n",
    "                super(GRUModel, self).__init__()\n",
    "                self.gru = nn.GRU(input_size, hidden_size, batch_first=True, dropout=0.2)\n",
    "                self.fc = nn.Linear(hidden_size, output_size)\n",
    "            \n",
    "            def forward(self, x):\n",
    "                gru_out, _ = self.gru(x)\n",
    "                gru_out = gru_out[:, -1, :] \n",
    "                out = self.fc(gru_out)\n",
    "                return out\n",
    "\n",
    "        time_steps = lag \n",
    "        input_size = 3 \n",
    "        hidden_size = 32\n",
    "        output_size = 1\n",
    "    \n",
    "        X_train, y_train, X_test, y_test, scaler_y = prepare_data_with_time_steps(data_LSTM, time_steps=time_steps)\n",
    "    \n",
    "        def train_and_evaluate_gru(X_train, y_train, X_test, y_test, input_size, hidden_size, output_size, num_epochs=100, lr=0.001):\n",
    "            gru_model = GRUModel(input_size=input_size, hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = torch.optim.Adam(gru_model.parameters(), lr=lr)\n",
    "            \n",
    "            for epoch in range(num_epochs):\n",
    "                gru_model.train()\n",
    "                optimizer.zero_grad()\n",
    "                output = gru_model(X_train)\n",
    "                loss = criterion(output, y_train)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "            gru_model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_train_pred = gru_model(X_train).cpu().numpy()\n",
    "                y_test_pred = gru_model(X_test).cpu().numpy()\n",
    "    \n",
    "            return y_train_pred, y_test_pred, y_train.cpu().numpy(), y_test.cpu().numpy(), gru_model\n",
    "    \n",
    "        y_train_pred, y_test_pred, y_train_actual, y_test_actual, gru_model = train_and_evaluate_gru(\n",
    "            X_train, y_train, X_test, y_test, input_size, hidden_size, output_size, num_epochs=100, lr=0.001\n",
    "        )\n",
    "    \n",
    "        y_train_pred = scaler_y.inverse_transform(y_train_pred)\n",
    "        y_test_pred = scaler_y.inverse_transform(y_test_pred)\n",
    "        y_train_actual = scaler_y.inverse_transform(y_train_actual)\n",
    "        y_test_actual = scaler_y.inverse_transform(y_test_actual)\n",
    "    \n",
    "        y_train_pred = y_train_pred.flatten()\n",
    "        y_test_pred = y_test_pred.flatten()\n",
    "        y_train_actual = y_train_actual.flatten()\n",
    "        y_test_actual = y_test_actual.flatten()\n",
    "    \n",
    "        plot_actual_vs_predicted(\n",
    "            y_test_actual,\n",
    "            y_test_pred,\n",
    "            model=gru_model,\n",
    "            data=data_LSTM,\n",
    "            forecast_steps=6,\n",
    "            selected_model='GRU'\n",
    "        )\n",
    "\n",
    "    elif selected_model == 'RF':\n",
    "        def prepare_data_with_lag(data):\n",
    "            X = data[[f'yt-{i}' for i in range(1, lag + 1)] + ['month_sin', 'month_cos']].values\n",
    "            y = data['chl_a'].values\n",
    "    \n",
    "            scaler_X = StandardScaler()\n",
    "            scaler_y = StandardScaler()\n",
    "    \n",
    "            X = scaler_X.fit_transform(X)\n",
    "            y = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "    \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "    \n",
    "            return X_train, y_train, X_test, y_test, scaler_y\n",
    "    \n",
    "        lag = 12  \n",
    "        X_train, y_train, X_test, y_test, scaler_y = prepare_data_with_lag(data)\n",
    "    \n",
    "        def train_and_evaluate_rf(X_train, y_train, X_test, y_test, n_estimators=100, max_depth=None):\n",
    "            rf_model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "            rf_model.fit(X_train, y_train)\n",
    "    \n",
    "            y_test_pred = rf_model.predict(X_test)\n",
    "    \n",
    "            y_test_pred_denorm = scaler_y.inverse_transform(y_test_pred.reshape(-1, 1)).flatten()\n",
    "            y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "    \n",
    "            return y_test_actual, y_test_pred_denorm, rf_model\n",
    "        actual_values, predicted_values, rf_model = train_and_evaluate_rf(X_train, y_train, X_test, y_test, n_estimators=100, max_depth=5)\n",
    "    \n",
    "        plot_actual_vs_predicted(actual_values, predicted_values, model=rf_model, data=data, forecast_steps=6, selected_model='RF')\n",
    "\n",
    "    elif selected_model == 'GPR':\n",
    "        def prepare_data_with_lag(data):\n",
    "            X = data[[f'yt-{i}' for i in range(1, lag + 1)] + ['month_sin', 'month_cos']].values\n",
    "            y = data['chl_a'].values\n",
    "            scaler_X = StandardScaler()\n",
    "            scaler_y = StandardScaler()\n",
    "    \n",
    "            X = scaler_X.fit_transform(X)\n",
    "            y = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "    \n",
    "            return X_train, y_train, X_test, y_test, scaler_y\n",
    "    \n",
    "        lag = 12  \n",
    "        X_train, y_train, X_test, y_test, scaler_y = prepare_data_with_lag(data)\n",
    "    \n",
    "        def train_and_evaluate_gpr(X_train, y_train, X_test, y_test):\n",
    "            kernel = ExpSineSquared(length_scale=1.0, periodicity=12.0) + WhiteKernel(noise_level=1e-5)\n",
    "            gpr_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=42)\n",
    "    \n",
    "            gpr_model.fit(X_train, y_train)\n",
    "    \n",
    "            y_test_pred = gpr_model.predict(X_test)\n",
    "    \n",
    "            y_test_pred_denorm = scaler_y.inverse_transform(y_test_pred.reshape(-1, 1)).flatten()\n",
    "            y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "    \n",
    "            return y_test_actual, y_test_pred_denorm, gpr_model\n",
    "        actual_values, predicted_values, gpr_model = train_and_evaluate_gpr(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "        plot_actual_vs_predicted(actual_values, predicted_values, model=gpr_model, data=data, forecast_steps=6, selected_model='GPR')\n",
    "\n",
    "    elif selected_model == 'SVR':\n",
    "\n",
    "        def prepare_data_with_lag(data):\n",
    "            X = data[[f'yt-{i}' for i in range(1, lag + 1)] + ['month_sin', 'month_cos']].values\n",
    "            y = data['chl_a'].values\n",
    "\n",
    "            scaler_X = StandardScaler()\n",
    "            scaler_y = StandardScaler()\n",
    "    \n",
    "            X = scaler_X.fit_transform(X)\n",
    "            y = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "    \n",
    "            return X_train, y_train, X_test, y_test, scaler_y\n",
    "\n",
    "        lag = 12  \n",
    "        X_train, y_train, X_test, y_test, scaler_y = prepare_data_with_lag(data)\n",
    "    \n",
    "        def train_and_evaluate_svr(X_train, y_train, X_test, y_test):\n",
    "            svr_model = SVR()\n",
    "            svr_model.fit(X_train, y_train)\n",
    "            y_test_pred = svr_model.predict(X_test)\n",
    "    \n",
    "            y_test_pred_denorm = scaler_y.inverse_transform(y_test_pred.reshape(-1, 1)).flatten()\n",
    "            y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "    \n",
    "            return y_test_actual, y_test_pred_denorm, svr_model\n",
    "    \n",
    "        actual_values, predicted_values, svr_model = train_and_evaluate_svr(X_train, y_train, X_test, y_test)\n",
    "        plot_actual_vs_predicted(actual_values, predicted_values, model=svr_model, data=data, forecast_steps=6, selected_model='SVR')\n",
    "\n",
    "# GUI Setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Chl-a Prediction Model GUI\")\n",
    "\n",
    "\n",
    "frame = tk.Frame(root)\n",
    "frame.pack(pady=50, padx=150)\n",
    "raw_data = None\n",
    "prepared_data = None\n",
    "model_var = tk.StringVar()\n",
    "forecast_entry = tk.Entry(frame)\n",
    "load_button = tk.Button(frame, text=\"Load CSV\", command=load_csv)\n",
    "load_button.pack(pady=10)\n",
    "next_button = tk.Button(frame, text=\"Next\", command=next_step)\n",
    "next_button.pack(pady=10)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32818506-d57a-4cc2-a0b2-f6728e17d8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
